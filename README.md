# Junior Data Scientist Portfolio
Meet me, Augustin, an aspiring data scientist, self-taught and highly motivated. With a strong passion for math, new technology, AI, machine learning, and computer vision, I spends most of my spare time on Kaggle, experimenting with new techniques and participating in data science competitions. I'm constantly learning from YouTube tutorials, Udemy bootcamps, EDx classes and exploring the latest technologies.  As an avid programmer who is constantly learning to stay on top of the latest trends in data science I am more then qualified to be your next candidate. 


## Education
### [HarvardX (EdX) - CS109x: Introduction to Data Science with Python](https://www.harvardonline.harvard.edu/course/introduction-data-science-python)
#### Grade: 100% - A
#### Course Outline:
- Linear Regression
- Multiple and Polynomial Regression
- Model Selection and Cross-Validation
- Bias, Variance, and Hyperparameters
- Classification and Logistic Regression
- Multi-logstic Regression and Missingness
- Bootstrap, Confidence Intervals, and Hypothesis Testing
- Capstone Project

### [HEC Montreal - Bachelor Business Administration / IT Specialisation](https://www.hec.ca/etudiants/mon-programme/baa/specialisations/specialisation-analyse-affaires-technologie-information.html)
#### Grade: 3.0
#### Program Outline:
- Python Introduction
- Web Development Introduction
- DataBase management
- Java Introduction
- Analytics and Statistics for business analysis
- Machine learning
- UI/UX
- Team work and management

## Projects
### [Project 1 - Wireless Volume Control](https://github.com/Augmaster/Augmaster.github.io/tree/main/Projects/WirelessVolumeChange)
#### Overview
The project uses a camera to track hand movements and gestures in real-time.It allows users to control their computer's volume by performing specific hand gestures.For example, getting your fingers closer can increase the volume while bringing spacing them can decrease it. The wireless nature of the project means that users can adjust their volume from a distance without having to touch their computer.
This technology could be applied to various other applications, such as smart home devices or gaming interfaces, making it a potentially useful addition to everyday life.

<img width="806" alt="image" src="https://user-images.githubusercontent.com/90472022/231293177-07680993-6ef4-4b86-a26d-ec3c218e174a.png">

[MediaPipe - Hand Tracking](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker)

#### The technologies I used: 
* OpenCV to process the camera input, detecting and tracking the hand movements.
* Mediapipe  to estimate the hand landmarks, providing accurate data for gesture recognition.
* Numpy for data processing and manipulation, allowing for efficient calculation of gesture characteristics.
* Osascript to control the volume of the computer (MAC).

![image](https://user-images.githubusercontent.com/90472022/231293425-01346230-5a9e-474b-a7dc-37b338fa3a1e.png)
